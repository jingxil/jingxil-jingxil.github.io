
 <!DOCTYPE HTML>
<html lang="default">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  
    <title>Decoding with Dynamic Vocabularies | CN Yah</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="Jingxi Liang">
    
    <meta name="description" content="Using dynamic vocabularies rather than the whole vocabularies(the size can be up to 50k) significantly reduces the costs during decoding. Also, narrow">
    
    
    
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/pacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/pacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

  <body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.svg" alt="CN Yah" title="CN Yah"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="CN Yah">CN Yah</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					
						<li><a href="/">Home</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="text" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:cnyah.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/11/decoding-with-dynamic-vocabularies/" title="Decoding with Dynamic Vocabularies" itemprop="url">Decoding with Dynamic Vocabularies</a>
  </h1>
  <p class="article-author">By
    
      <a href="http://cnyah.com" title="Jingxi Liang">Jingxi Liang</a>
    </p>
  <p class="article-time">
    <time datetime="2018-01-11T06:54:01.000Z" itemprop="datePublished">2018-11-01</time>
    Updated:<time datetime="2018-01-11T06:16:35.000Z" itemprop="dateModified">2018-11-01</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Motivation"><span class="toc-number">1.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model"><span class="toc-number">2.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Objective-Function"><span class="toc-number">3.</span> <span class="toc-text">Objective Function</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Experiment-Setup"><span class="toc-number">4.</span> <span class="toc-text">Experiment Setup</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">5.</span> <span class="toc-text">Reference</span></a></li></ol>
		</div>
		
		<p>Using dynamic vocabularies rather than the whole vocabularies(the size can be up to 50k) significantly reduces the costs during decoding. Also, narrowing the candidates by removing totally irrelevant vocabularies should boost model’s performance. </p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>To tackle the ‘safe reply’ problem in neural conversation models, there are models using MMI to avoid common responses <a href="http://cnyah.com/2017/07/03/penalize-way-too-common-reponses/">link</a>, models taking conversation history into consideration, models biasing responses to some speciﬁc persona or emotions, models weighting beam search results to get a better response. Yu Wu et al.[1] proposed to factorize the generation probability $p(Y_{i}|X_{i})$ as the product of a vocabulary generation probability conditioned on the input $p(T_{i}|X_{i})$ and a response generation probability conditioned on both the input and the dynamic vocabulary $p(Y_{i}|T_{i},X_{i})$.<br>$$<br>p(Y_{i}|X_{i})=p(Y_{i}|T_{i},X_{i})p(T_{i}|X_{i})<br>$$</p>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>The Dynamic Vocabulary Sequence to Sequence (DVS2S) is based on the seq2seq model. The key part is how the dynamic vocabulary is constructed. Let us make this assumption that for each $X_{i}$, Target Vocabulary $T_{i}$ is sampled from a multivariate Bernoulli distribution $(\beta_{i,1} … \beta_{i,|V|}) $ where $\beta_{i,j}$ is the probability of the j-th word being selected to generate the response to $X_{i}$. </p>
<p>Further more, $T_{i}$ can be decomposed to the union of content words $T_{i}^{c}$ and function words $T_{i}^{f}$. Function words guarantee grammatical correctness and ﬂuency of responses. Therefore, $T_{i}^{f}$ should not vary very much. They collect words appearing more than 10 times in the training data, excluding nouns, verbs, adjectives and adverbs from them, and use the remaining ones to form a function word set and make their $\beta = 1$. Content words, on the other hand, express semantics of responses, and thus should be highly related to the input message. For $ \forall c \in T_{i}^{c} $, $ \beta_{I(c)} $ is defined as<br>$$<br>\beta_{I(c)} = \sigma(W_{c}h_{t}+b_{c})<br>$$<br>where $h_{t}$ is the last hidden state of the encoder. </p>
<p><img src="model.png" alt="model"></p>
<h2 id="Objective-Function"><a href="#Objective-Function" class="headerlink" title="Objective Function"></a>Objective Function</h2><p>To allocate a proper $T$ to $X$ is key to the success of DVS2S. To make sure that, they consider jointly learning vocabulary construction and response generation from training data. The Log Likelihood is<br>$$<br>L = \sum^{N}_{i=1}\log(\sum_{T_{i}}p(Y_{i}|T_{i},X_{i})p(T_{i}|X_{i}))<br>$$</p>
<p>The objective function above is difﬁcult to optimize as logarithm is outside the summation. By Jensen’s Inequality, we have<br>$$<br>L \ge \sum^{N}_{i=1}\sum_{T_{i}}p(T_{i}|X_{i})\log(p(Y_{i}|T_{i},X_{i}))<br>$$<br>Hence, we can instead maximize the lower bound. Note the size of $T_{i}$ is $2^{|V|}$ which means it is impossible to sum over all samples of $T_{i}$. Alternatively, we can employ the Monte Carlo sampling to approximate $T_{i}$. Let’s say we have samples S which leads to<br>$$<br>L_{i} = \frac{1}{|S|}\sum_{S}\log(p(Y_{i}|T_{i},X_{i}))<br>$$</p>
<p>While the computation is feasible $p(T_{i}|X_{i})$ is gone. There is no guide how to update $\beta$s. The trick (at least I think it is a trick) is to rewrite the gradient with respect to all parameters $\Theta$ of L as</p>
<p>$$<br>\begin{eqnarray}<br>\frac{dL_{i}(\Theta)}{d\Theta} \\<br>= \sum_{T_{i}} p(T_{i}|X_{i})\frac{d\log(p(Y_{i}|T_{i},X_{i})}{d\Theta} + \log p(Y_{i}|T_{i},X_{i})\frac{dp(T_{i}|X_{i})}{d\Theta} \\<br>= \sum_{T_{i}} p(T_{i}|X_{i})\frac{d\log(p(Y_{i}|T_{i},X_{i})}{d\Theta} + p(T_{i}|X_{i}) \log p(Y_{i}|T_{i},X_{i})\frac{d\log p(T_{i}|X_{i})}{d\Theta} \\<br>= \sum_{T_{i}} p(T_{i}|X_{i})[\frac{d\log(p(Y_{i}|T_{i},X_{i})}{d\Theta} + \log p(Y_{i}|T_{i},X_{i})\frac{d\log p(T_{i}|X_{i})}{d\Theta}]\\<br>\end{eqnarray}<br>$$</p>
<p>Now use samples S instead of $T_{i}$ and we get<br>$$<br>\frac{1}{|S|}\sum_{S}[\frac{d\log(p(Y_{i}|T_{i},X_{i})}{d\Theta} + \log p(Y_{i}|T_{i},X_{i})\frac{d\log p(T_{i}|X_{i})}{d\Theta}]<br>$$</p>
<p>To reduce variance, they normalize the gradient with the length of the response and introduce a moving average baseline $b_{k}$ to the gradient. Now the gradient with respect to all parameters $\Theta$ of L is<br>$$<br>\frac{dL_{i}(\Theta)}{d\Theta} \approx \frac{1}{|S|}\sum_{S}[\frac{d\log(p(Y_{i}|T_{i},X_{i})}{d\Theta} + (\frac{1}{m}\log p(Y_{i}|T_{i},X_{i})- b_{k}) \frac{d\log p(T_{i}|X_{i})}{d\Theta}]<br>$$</p>
<h2 id="Experiment-Setup"><a href="#Experiment-Setup" class="headerlink" title="Experiment Setup"></a>Experiment Setup</h2><ul>
<li>The vocab size is 30,000 words that cover 98.8% and 98.3% of words.</li>
<li>The number of samples S is 5.</li>
<li>Word embedding size is 620.</li>
<li>Hidden vector size is 1024.</li>
<li>Target vocabulary contains 701 function words and top 1,000 content words.</li>
<li>Beam size as 20.</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Yu Wu et al. Neural Response Generation with Dynamic Vocabularies. AAAI 2018</p>
  
	</div>
		<footer class="article-footer clearfix">

  <div class="article-tags">
  
  <span></span> <a href="/tags/summary/">summary</a><a href="/tags/seq2seq/">seq2seq</a>
  </div>




<div class="article-share" id="share">

  <div data-url="http://cnyah.com/2018/01/11/decoding-with-dynamic-vocabularies/" data-title="Decoding with Dynamic Vocabularies | CN Yah" data-tsina="null" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/01/29/dNDF/" title="Deep Neural Decision Forests">
  <strong>PREVIOUS:</strong><br/>
  <span>
  Deep Neural Decision Forests</span>
</a>
</div>


<div class="next">
<a href="/2018/01/03/computer-vision-project-summary/"  title="Computer Vision Project Summary">
 <strong>NEXT:</strong><br/> 
 <span>Computer Vision Project Summary
</span>
</a>
</div>

</nav>

	
</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Motivation"><span class="toc-number">1.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model"><span class="toc-number">2.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Objective-Function"><span class="toc-number">3.</span> <span class="toc-text">Objective Function</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Experiment-Setup"><span class="toc-number">4.</span> <span class="toc-text">Experiment Setup</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">5.</span> <span class="toc-text">Reference</span></a></li></ol>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  

  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			<li><a href="/tags/CV/" title="CV">CV<sup>1</sup></a></li>
		
			<li><a href="/tags/GAN/" title="GAN">GAN<sup>1</sup></a></li>
		
			<li><a href="/tags/NLI/" title="NLI">NLI<sup>1</sup></a></li>
		
			<li><a href="/tags/NN/" title="NN">NN<sup>1</sup></a></li>
		
			<li><a href="/tags/POS-tagging/" title="POS tagging">POS tagging<sup>1</sup></a></li>
		
			<li><a href="/tags/RL/" title="RL">RL<sup>1</sup></a></li>
		
			<li><a href="/tags/RNN/" title="RNN">RNN<sup>4</sup></a></li>
		
			<li><a href="/tags/chatbot/" title="chatbot">chatbot<sup>1</sup></a></li>
		
			<li><a href="/tags/collections/" title="collections">collections<sup>3</sup></a></li>
		
			<li><a href="/tags/machine-comprehension/" title="machine comprehension">machine comprehension<sup>4</sup></a></li>
		
			<li><a href="/tags/notes/" title="notes">notes<sup>1</sup></a></li>
		
			<li><a href="/tags/others/" title="others">others<sup>2</sup></a></li>
		
			<li><a href="/tags/project/" title="project">project<sup>1</sup></a></li>
		
			<li><a href="/tags/seq2seq/" title="seq2seq">seq2seq<sup>9</sup></a></li>
		
			<li><a href="/tags/summary/" title="summary">summary<sup>20</sup></a></li>
		
			<li><a href="/tags/word-embeddings/" title="word embeddings">word embeddings<sup>2</sup></a></li>
		
		</ul>
</div>


  
  <div class="archiveslist">
    <p class="asidetitle"><a href="/archives">Archives</a></p>
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a><span class="archive-list-count">2</span></li></ul>
  </div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<div class="social-font clearfix">
		
		
		
		<a href="https://github.com/jingxil" target="_blank" title="github"></a>
		
		
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/A-limon/pacman" target="_blank" title="Pacman">Pacman</a> © 2018 
		
		<a href="http://cnyah.com" target="_blank" title="Jingxi Liang">Jingxi Liang</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>





<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-50558696-1', 'cnyah.com');  
ga('send', 'pageview');
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  </body>
</html>

